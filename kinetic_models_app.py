import streamlit as st
import hashlib
from datetime import datetime, timezone
import hmac
import time

# =============================================================================
# ===== IN√çCIO DO C√ìDIGO DE PROTE√á√ÉO FINAL ====================================
# =============================================================================
def init_connection():
    """Inicializa conex√£o com Supabase. Requer secrets configurados."""
    try:
        from st_supabase_connection import SupabaseConnection
        return st.connection("supabase", type=SupabaseConnection)
    except Exception as e:
        st.error(f"Erro ao conectar com Supabase: {e}")
        return None

def verify_and_consume_nonce(token: str) -> tuple[bool, str | None]:
    """Verifica um token de uso √∫nico (nonce) no banco de dados e o consome."""
    conn = init_connection()
    if not conn:
        return False, None

    try:
        # 1. Cria o hash do token recebido para procurar no banco
        token_hash = hashlib.sha256(token.encode()).hexdigest()
        
        # 2. Procura pelo token no banco de dados
        response = conn.table("auth_tokens").select("*").eq("token_hash", token_hash).execute()
        
        if not response.data:
            st.error("Token de acesso inv√°lido ou n√£o encontrado.")
            return False, None
        
        token_data = response.data[0]
        
        # 3. Verifica se o token j√° foi utilizado
        if token_data["is_used"]:
            st.error("Este link de acesso j√° foi utilizado e n√£o √© mais v√°lido.")
            return False, None
            
        # 4. Verifica se o token expirou
        expires_at = datetime.fromisoformat(token_data["expires_at"])
        if datetime.now(timezone.utc) > expires_at:
            st.error("O link de acesso expirou. Por favor, gere um novo no portal.")
            return False, None
            
        # 5. Se tudo estiver correto, marca o token como usado (consumido)
        conn.table("auth_tokens").update({"is_used": True}).eq("id", token_data["id"]).execute()
        
        user_email = token_data["user_email"]
        return True, user_email
        
    except Exception as e:
        st.error(f"Ocorreu um erro cr√≠tico durante a valida√ß√£o do acesso: {e}")
        return False, None

def verify_auth_token(token: str, secret_key: str) -> tuple:
    """Verifica um token de autentica√ß√£o HMAC-SHA256 com timestamp."""
    try:
        parts = token.split(':')
        if len(parts) != 3:
            return False, None
        
        email, timestamp, signature = parts
        
        # 1. Verifica se o token expirou (validade de 1 hora)
        if int(time.time()) - int(timestamp) > 3600:
            st.error("Token de autentica√ß√£o expirado.")
            return False, None
        
        # 2. Recria a assinatura esperada para verifica√ß√£o
        message = f"{email}:{timestamp}"
        expected_signature = hmac.new(secret_key.encode(), message.encode(), hashlib.sha256).hexdigest()
        
        # 3. Compara as assinaturas de forma segura
        if hmac.compare_digest(signature, expected_signature):
            return True, email
        else:
            st.error("Token de autentica√ß√£o inv√°lido.")
            return False, None
            
    except Exception as e:
        st.error(f"Erro ao verificar token: {e}")
        return False, None

def check_authentication():
    """Verifica autentica√ß√£o usando sistema duplo: Supabase + HMAC fallback"""
    # --- L√≥gica Principal de Autentica√ß√£o ---
    query_params = st.query_params
    access_token = query_params.get("access_token")
    auth_token = query_params.get("auth_token")

    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False

    # Primeiro tenta Supabase (access_token)
    if access_token and not st.session_state.authenticated:
        time.sleep(1)  # PAUSA ESTRAT√âGICA PARA EVITAR RACE CONDITION
        is_valid, email = verify_and_consume_nonce(access_token)
        if is_valid:
            st.session_state.authenticated = True
            st.session_state.user_email = email
            return True

    # Fallback para HMAC (auth_token)
    if auth_token and not st.session_state.authenticated:
        try:
            auth_secrets = st.secrets.get("auth", {})
            secret_key = auth_secrets.get("token_secret_key")

            if secret_key:
                is_valid, email = verify_auth_token(auth_token, secret_key)
                if is_valid:
                    st.session_state.authenticated = True
                    st.session_state.user_email = email
                    return True
            else:
                st.error("Chave secreta de autentica√ß√£o n√£o configurada no aplicativo.")
                
        except Exception as e:
            st.error(f"Ocorreu um erro durante a autentica√ß√£o: {e}")

    return st.session_state.get('authenticated', False)

def show_access_denied():
    """Mostra p√°gina de acesso negado"""
    st.title("üîí Acesso Restrito")
    st.error("Este aplicativo requer autentica√ß√£o. Por favor, fa√ßa o login atrav√©s do portal.")
    
    st.link_button(
        "Ir para o Portal de Login",
        "https://huggingface.co/spaces/MarioNunes34/Portal",
        use_container_width=True,
        type="primary"
    )
    st.stop()

# =============================================================================
# ===== FIM DO C√ìDIGO DE PROTE√á√ÉO =============================================
# =============================================================================

# Verifica√ß√£o de autentica√ß√£o
if not check_authentication():
    show_access_denied()

# Mensagem de boas-vindas para o usu√°rio autenticado
st.success(f"Autentica√ß√£o bem-sucedida! Bem-vindo, {st.session_state.get('user_email', 'usu√°rio')}.")

# =============================================================================
# ===== IN√çCIO DO APLICATIVO PRINCIPAL ======================================
# =============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
import io
from datetime import datetime

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Ajuste de Modelos Cin√©ticos", layout="wide")

# T√≠tulo
st.title("Ajuste de Modelos Cin√©ticos")
st.markdown("**Modelos dispon√≠veis:** Pseudo-Second Order, Intraparticle Diffusion, Elovich")

# Defini√ß√£o dos modelos cin√©ticos
def pseudo_second_order(t, k2, qe):
    """Modelo Pseudo-Segunda Ordem: qt = (k2 * qe¬≤ * t) / (1 + k2 * qe * t)"""
    return (k2 * qe**2 * t) / (1 + k2 * qe * t)

def intraparticle_diffusion(t, kp, C):
    """Modelo de Difus√£o Intrapart√≠cula: qt = kp * sqrt(t) + C"""
    return kp * np.sqrt(t) + C

def elovich(t, alpha, beta):
    """Modelo de Elovich: qt = (1/beta) * ln(alpha * beta) + (1/beta) * ln(t)"""
    with np.errstate(divide='ignore', invalid='ignore'):
        result = (1/beta) * np.log(alpha * beta) + (1/beta) * np.log(t)
        # Substituir valores inv√°lidos por 0
        result = np.where(np.isfinite(result), result, 0)
    return result

# Fun√ß√£o para gerar curvas suaves
def generate_smooth_curve(model_name, params, t_data, n_points=200):
    """Gera curva suave para o modelo especificado"""
    t_smooth = np.linspace(np.min(t_data), np.max(t_data), n_points)
    
    if model_name == 'Pseudo-Second Order':
        qt_smooth = pseudo_second_order(t_smooth, params['k2'], params['qe'])
    elif model_name == 'Intraparticle Diffusion':
        qt_smooth = intraparticle_diffusion(t_smooth, params['kp'], params['C'])
    elif model_name == 'Elovich':
        qt_smooth = elovich(t_smooth, params['alpha'], params['beta'])
    else:
        return None, None
    
    return t_smooth, qt_smooth

# Fun√ß√£o para calcular R¬≤
def r_squared(y_observed, y_predicted):
    ss_res = np.sum((y_observed - y_predicted) ** 2)
    ss_tot = np.sum((y_observed - np.mean(y_observed)) ** 2)
    return 1 - (ss_res / ss_tot)

# Fun√ß√£o para calcular R¬≤ ponderado
def weighted_r_squared(y_observed, y_predicted, weights):
    """Calcula R¬≤ ponderado considerando os pesos (inverso da vari√¢ncia)"""
    mean_obs = np.average(y_observed, weights=weights)
    ss_res = np.sum(weights * (y_observed - y_predicted) ** 2)
    ss_tot = np.sum(weights * (y_observed - mean_obs) ** 2)
    return 1 - (ss_res / ss_tot)

# Fun√ß√£o para calcular chi-quadrado reduzido
def reduced_chi_squared(y_observed, y_predicted, sigma, n_params):
    """Calcula chi-quadrado reduzido"""
    chi_sq = np.sum(((y_observed - y_predicted) / sigma) ** 2)
    degrees_freedom = len(y_observed) - n_params
    return chi_sq / degrees_freedom if degrees_freedom > 0 else np.inf

# Fun√ß√£o para ajustar modelos com desvio padr√£o
def fit_models(t_data, qt_data, sigma_data=None):
    results = {}
    
    # Se n√£o h√° desvio padr√£o, usar peso uniforme
    if sigma_data is None:
        sigma_data = np.ones_like(qt_data)
        use_weights = False
    else:
        use_weights = True
    
    # Evitar divis√£o por zero e valores muito pequenos
    sigma_data = np.where(sigma_data <= 0, np.mean(sigma_data[sigma_data > 0]) if np.any(sigma_data > 0) else 1, sigma_data)
    weights = 1 / (sigma_data ** 2)  # Peso = 1/œÉ¬≤
    
    # Pseudo-Second Order
    try:
        # Estimativas iniciais
        qe_max = np.max(qt_data)
        k2_init = 0.01
        
        popt_pso, pcov_pso = curve_fit(
            pseudo_second_order, 
            t_data, 
            qt_data, 
            p0=[k2_init, qe_max],
            sigma=sigma_data,
            absolute_sigma=True,
            bounds=([0, 0], [np.inf, np.inf]),
            maxfev=5000
        )
        
        qt_pred_pso = pseudo_second_order(t_data, *popt_pso)
        
        # Calcular m√©tricas
        if use_weights:
            r2_pso = weighted_r_squared(qt_data, qt_pred_pso, weights)
            chi2_red_pso = reduced_chi_squared(qt_data, qt_pred_pso, sigma_data, 2)
        else:
            r2_pso = r_squared(qt_data, qt_pred_pso)
            chi2_red_pso = None
        
        # Calcular incertezas dos par√¢metros
        param_std_pso = np.sqrt(np.diag(pcov_pso))
        
        results['Pseudo-Second Order'] = {
            'params': {'k2': popt_pso[0], 'qe': popt_pso[1]},
            'param_std': {'k2_std': param_std_pso[0], 'qe_std': param_std_pso[1]},
            'r2': r2_pso,
            'chi2_red': chi2_red_pso,
            'qt_pred': qt_pred_pso,
            'equation': f'qt = ({popt_pso[0]:.4f}¬±{param_std_pso[0]:.4f}) √ó ({popt_pso[1]:.4f}¬±{param_std_pso[1]:.4f})¬≤ √ó t / (1 + ({popt_pso[0]:.4f}¬±{param_std_pso[0]:.4f}) √ó ({popt_pso[1]:.4f}¬±{param_std_pso[1]:.4f}) √ó t)',
            'n_params': 2
        }
    except Exception as e:
        st.warning(f"N√£o foi poss√≠vel ajustar o modelo Pseudo-Second Order: {str(e)}")
        results['Pseudo-Second Order'] = None
    
    # Intraparticle Diffusion
    try:
        popt_ipd, pcov_ipd = curve_fit(
            intraparticle_diffusion, 
            t_data, 
            qt_data,
            sigma=sigma_data,
            absolute_sigma=True,
            maxfev=5000
        )
        
        qt_pred_ipd = intraparticle_diffusion(t_data, *popt_ipd)
        
        # Calcular m√©tricas
        if use_weights:
            r2_ipd = weighted_r_squared(qt_data, qt_pred_ipd, weights)
            chi2_red_ipd = reduced_chi_squared(qt_data, qt_pred_ipd, sigma_data, 2)
        else:
            r2_ipd = r_squared(qt_data, qt_pred_ipd)
            chi2_red_ipd = None
        
        # Calcular incertezas dos par√¢metros
        param_std_ipd = np.sqrt(np.diag(pcov_ipd))
        
        results['Intraparticle Diffusion'] = {
            'params': {'kp': popt_ipd[0], 'C': popt_ipd[1]},
            'param_std': {'kp_std': param_std_ipd[0], 'C_std': param_std_ipd[1]},
            'r2': r2_ipd,
            'chi2_red': chi2_red_ipd,
            'qt_pred': qt_pred_ipd,
            'equation': f'qt = ({popt_ipd[0]:.4f}¬±{param_std_ipd[0]:.4f}) √ó ‚àöt + ({popt_ipd[1]:.4f}¬±{param_std_ipd[1]:.4f})',
            'n_params': 2
        }
    except Exception as e:
        st.warning(f"N√£o foi poss√≠vel ajustar o modelo Intraparticle Diffusion: {str(e)}")
        results['Intraparticle Diffusion'] = None
    
    # Elovich
    try:
        # Filtrar valores de t > 0 para evitar log(0)
        valid_indices = t_data > 0
        t_valid = t_data[valid_indices]
        qt_valid = qt_data[valid_indices]
        sigma_valid = sigma_data[valid_indices]
        
        if len(t_valid) > 2:  # Precisamos de pelo menos 3 pontos
            # Estimativas iniciais
            alpha_init = 1.0
            beta_init = 0.1
            
            popt_elo, pcov_elo = curve_fit(
                elovich, 
                t_valid, 
                qt_valid,
                p0=[alpha_init, beta_init],
                sigma=sigma_valid,
                absolute_sigma=True,
                bounds=([0.001, 0.001], [np.inf, np.inf]),
                maxfev=5000
            )
            
            qt_pred_elo = elovich(t_data, *popt_elo)
            
            # Calcular m√©tricas
            if use_weights:
                weights_valid = 1 / (sigma_valid ** 2)
                qt_pred_valid = elovich(t_valid, *popt_elo)
                r2_elo = weighted_r_squared(qt_valid, qt_pred_valid, weights_valid)
                chi2_red_elo = reduced_chi_squared(qt_valid, qt_pred_valid, sigma_valid, 2)
            else:
                r2_elo = r_squared(qt_data, qt_pred_elo)
                chi2_red_elo = None
            
            # Calcular incertezas dos par√¢metros
            param_std_elo = np.sqrt(np.diag(pcov_elo))
            
            results['Elovich'] = {
                'params': {'alpha': popt_elo[0], 'beta': popt_elo[1]},
                'param_std': {'alpha_std': param_std_elo[0], 'beta_std': param_std_elo[1]},
                'r2': r2_elo,
                'chi2_red': chi2_red_elo,
                'qt_pred': qt_pred_elo,
                'equation': f'qt = ({1/popt_elo[1]:.4f}¬±{param_std_elo[1]/(popt_elo[1]**2):.4f}) √ó ln(({popt_elo[0]:.4f}¬±{param_std_elo[0]:.4f}) √ó ({popt_elo[1]:.4f}¬±{param_std_elo[1]:.4f})) + ({1/popt_elo[1]:.4f}¬±{param_std_elo[1]/(popt_elo[1]**2):.4f}) √ó ln(t)',
                'n_params': 2
            }
        else:
            st.warning("Dados insuficientes para ajustar o modelo Elovich (necess√°rio t > 0)")
            results['Elovich'] = None
    except Exception as e:
        st.warning(f"N√£o foi poss√≠vel ajustar o modelo Elovich: {str(e)}")
        results['Elovich'] = None
    
    return results, use_weights

# Interface do usu√°rio
st.sidebar.header("Upload dos Dados")

uploaded_file = st.sidebar.file_uploader(
    "Carregue seu arquivo Excel",
    type=['xlsx', 'xls'],
    help="O arquivo deve conter tr√™s colunas: tempo, qe e desvio padr√£o de qe"
)

if uploaded_file is not None:
    try:
        # Ler arquivo Excel
        df = pd.read_excel(uploaded_file)
        
        st.sidebar.success("Arquivo carregado com sucesso!")
        
        # Mostrar pr√©via dos dados
        st.subheader("Pr√©via dos Dados")
        st.dataframe(df.head())
        
        # Sele√ß√£o de colunas
        st.sidebar.subheader("Sele√ß√£o de Colunas")
        
        time_col = st.sidebar.selectbox(
            "Selecione a coluna de tempo:",
            df.columns,
            index=0
        )
        
        qt_col = st.sidebar.selectbox(
            "Selecione a coluna de qe:",
            df.columns,
            index=1 if len(df.columns) > 1 else 0
        )
        
        sigma_col = st.sidebar.selectbox(
            "Selecione a coluna de desvio padr√£o de qe:",
            ['Nenhuma (sem peso)'] + list(df.columns),
            index=2 if len(df.columns) > 2 else 0
        )
        
        # Mostrar informa√ß√µes sobre os dados carregados
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("N√∫mero de pontos", len(df))
        with col2:
            st.metric("Colunas dispon√≠veis", len(df.columns))
        with col3:
            has_errors = sigma_col != 'Nenhuma (sem peso)'
            st.metric("Desvios padr√£o", "Sim" if has_errors else "N√£o")
        
        if sigma_col != 'Nenhuma (sem peso)':
            st.success("‚úÖ Desvios padr√£o detectados - Ser√° realizado ajuste ponderado")
        else:
            st.info("‚ÑπÔ∏è Sem desvios padr√£o - Ser√° realizado ajuste com pesos uniformes")
        
        # Op√ß√£o para mostrar barras de erro
        show_error_bars = st.sidebar.checkbox("Mostrar barras de erro nos gr√°ficos", value=True)
        
        # Bot√£o para limpar cache
        if st.sidebar.button("üßπ Limpar Cache/Resultados", help="Limpa todos os resultados anteriores"):
            for key in list(st.session_state.keys()):
                if key in ['results', 't_data', 'qt_data', 'sigma_data', 'time_col', 'qt_col', 'sigma_col', 'use_weights', 'show_error_bars', 'n_curve_points']:
                    del st.session_state[key]
            st.success("Cache limpo! Carregue seus dados novamente.")
            st.rerun()
        
        # Configura√ß√µes de exporta√ß√£o
        st.sidebar.subheader("Configura√ß√µes de Exporta√ß√£o")
        n_curve_points = st.sidebar.slider(
            "N√∫mero de pontos nas curvas suaves:",
            min_value=100,
            max_value=1000,
            value=300,
            step=50,
            help="Mais pontos = curvas mais suaves, mas arquivo maior"
        )
        
        if st.sidebar.button("Ajustar Modelos"):
            # LIMPAR DADOS ANTIGOS DO SESSION STATE
            for key in ['results', 't_data', 'qt_data', 'sigma_data', 'time_col', 'qt_col', 'sigma_col', 'use_weights', 'show_error_bars', 'n_curve_points']:
                if key in st.session_state:
                    del st.session_state[key]
            
            # Preparar dados
            t_data = df[time_col].values
            qt_data = df[qt_col].values
            
            # Preparar dados de desvio padr√£o
            if sigma_col != 'Nenhuma (sem peso)':
                sigma_data = df[sigma_col].values
            else:
                sigma_data = None
            
            # Remover valores NaN
            if sigma_data is not None:
                valid_mask = ~(np.isnan(t_data) | np.isnan(qt_data) | np.isnan(sigma_data))
                sigma_data = sigma_data[valid_mask]
            else:
                valid_mask = ~(np.isnan(t_data) | np.isnan(qt_data))
            
            t_data = t_data[valid_mask]
            qt_data = qt_data[valid_mask]
            
            if len(t_data) < 3:
                st.error("Dados insuficientes para ajuste (m√≠nimo 3 pontos)")
            else:
                # Mostrar informa√ß√µes dos dados carregados para debug
                st.info(f"üìä **Dados carregados:** {len(t_data)} pontos | Tempo: {t_data.min():.2f} - {t_data.max():.2f} | qt: {qt_data.min():.2f} - {qt_data.max():.2f}")
                
                # Ajustar modelos
                peso_text = "com pesos baseados no desvio padr√£o" if sigma_col != 'Nenhuma (sem peso)' else "com pesos uniformes"
                with st.spinner(f"Ajustando modelos {peso_text}..."):
                    results, use_weights = fit_models(t_data, qt_data, sigma_data)
                
                # Armazenar resultados no session state com valida√ß√£o
                st.session_state.results = results
                st.session_state.t_data = t_data.copy()  # Fazer c√≥pia para evitar refer√™ncias
                st.session_state.qt_data = qt_data.copy()
                st.session_state.sigma_data = sigma_data.copy() if sigma_data is not None else None
                st.session_state.time_col = time_col
                st.session_state.qt_col = qt_col
                st.session_state.sigma_col = sigma_col
                st.session_state.use_weights = use_weights
                st.session_state.show_error_bars = show_error_bars
                st.session_state.n_curve_points = n_curve_points
                
                # Debug: Mostrar hash dos dados para confirmar
                data_hash = hash(tuple(t_data)) + hash(tuple(qt_data))
                st.session_state.data_hash = data_hash
                st.info(f"üìä **Dados processados com sucesso!** Hash: {data_hash}")
                
                # Mostrar resultado do ajuste
                successful_models = [name for name, data in results.items() if data is not None]
                if successful_models:
                    st.success(f"‚úÖ Ajuste conclu√≠do! Modelos ajustados: {', '.join(successful_models)}")
                else:
                    st.error("‚ùå Nenhum modelo p√¥de ser ajustado aos dados")
    
    except Exception as e:
        st.error(f"Erro ao processar o arquivo: {str(e)}")

# Mostrar resultados se existirem
if 'results' in st.session_state:
    # Validar integridade dos dados
    required_keys = ['results', 't_data', 'qt_data', 'use_weights', 'show_error_bars']
    if not all(key in st.session_state for key in required_keys):
        st.error("‚ùå Dados inconsistentes detectados. Clique em 'Limpar Cache' e tente novamente.")
        st.stop()
    
    results = st.session_state.results
    t_data = st.session_state.t_data
    qt_data = st.session_state.qt_data
    sigma_data = st.session_state.sigma_data
    use_weights = st.session_state.use_weights
    show_error_bars = st.session_state.show_error_bars
    n_curve_points = st.session_state.get('n_curve_points', 300)
    
    # Mostrar hash para debug
    if 'data_hash' in st.session_state:
        current_hash = hash(tuple(t_data)) + hash(tuple(qt_data))
        if current_hash != st.session_state.data_hash:
            st.error("‚ö†Ô∏è Dados foram alterados! Recalcule os modelos.")
            st.stop()
        else:
            st.success(f"‚úÖ Dados √≠ntegros (Hash: {current_hash})")
    
    # Criar abas para cada modelo
    tab1, tab2, tab3, tab4 = st.tabs(["Resumo", "Pseudo-Second Order", "Intraparticle Diffusion", "Elovich"])
    
    with tab1:
        st.subheader("Resumo dos Ajustes")
        
        if use_weights:
            st.info("üìä **Ajuste ponderado realizado** - Os desvios padr√£o foram considerados como pesos no ajuste")
        else:
            st.info("üìä **Ajuste sem pesos** - Todos os pontos t√™m o mesmo peso")
        
        summary_data = []
        for model_name, model_data in results.items():
            if model_data is not None:
                chi2_text = f"{model_data['chi2_red']:.4f}" if model_data['chi2_red'] is not None else "N/A"
                summary_data.append({
                    'Modelo': model_name,
                    'R¬≤': f"{model_data['r2']:.4f}",
                    'œá¬≤ reduzido': chi2_text,
                    'Equa√ß√£o': model_data['equation']
                })
        
        if summary_data:
            summary_df = pd.DataFrame(summary_data)
            st.dataframe(summary_df, use_container_width=True)
            
            # Gr√°fico comparativo
            fig, ax = plt.subplots(figsize=(12, 8))
            
            # Criar pontos suaves para as curvas
            t_smooth = np.linspace(np.min(t_data), np.max(t_data), n_curve_points)
            
            # Dados experimentais com barras de erro
            if sigma_data is not None and show_error_bars:
                ax.errorbar(t_data, qt_data, yerr=sigma_data, fmt='o', 
                           color='black', capsize=3, capthick=1, 
                           label='Dados Experimentais', zorder=5)
            else:
                ax.scatter(t_data, qt_data, color='black', s=50, 
                          label='Dados Experimentais', zorder=5)
            
            # Modelos ajustados com curvas suaves
            colors = ['red', 'blue', 'green']
            for i, (model_name, model_data) in enumerate(results.items()):
                if model_data is not None:
                    # Calcular predi√ß√µes suaves baseadas nos par√¢metros ajustados
                    t_curve, qt_curve = generate_smooth_curve(model_name, model_data['params'], t_data, n_curve_points)
                    if t_curve is not None and qt_curve is not None:
                        chi2_text = f", œá¬≤ = {model_data['chi2_red']:.3f}" if model_data['chi2_red'] is not None else ""
                        ax.plot(t_curve, qt_curve, 
                               color=colors[i % len(colors)], 
                               linewidth=2, 
                               label=f"{model_name} (R¬≤ = {model_data['r2']:.4f}{chi2_text})")
            
            ax.set_xlabel('Tempo')
            ax.set_ylabel('qt')
            ax.set_title('Compara√ß√£o dos Modelos Cin√©ticos' + (' (com pesos)' if use_weights else ''))
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            st.pyplot(fig)
        else:
            st.error("Nenhum modelo foi ajustado com sucesso")
    
    # Abas individuais para cada modelo
    model_tabs = [tab2, tab3, tab4]
    model_names = ["Pseudo-Second Order", "Intraparticle Diffusion", "Elovich"]
    
    for tab, model_name in zip(model_tabs, model_names):
        with tab:
            model_data = results.get(model_name)
            
            if model_data is not None:
                st.subheader(f"Modelo {model_name}")
                
                # Par√¢metros com incertezas
                st.write("**Par√¢metros:**")
                for param, value in model_data['params'].items():
                    param_std_key = f"{param}_std"
                    if param_std_key in model_data['param_std']:
                        uncertainty = model_data['param_std'][param_std_key]
                        st.write(f"- {param}: {value:.6f} ¬± {uncertainty:.6f}")
                    else:
                        st.write(f"- {param}: {value:.6f}")
                
                st.write(f"**R¬≤:** {model_data['r2']:.6f}")
                if model_data['chi2_red'] is not None:
                    st.write(f"**œá¬≤ reduzido:** {model_data['chi2_red']:.6f}")
                st.write(f"**Equa√ß√£o:** {model_data['equation']}")
                
                # Gr√°fico individual
                fig, ax = plt.subplots(figsize=(10, 6))
                
                # Dados experimentais com barras de erro
                if sigma_data is not None and show_error_bars:
                    ax.errorbar(t_data, qt_data, yerr=sigma_data, fmt='o', 
                               color='black', capsize=3, capthick=1, 
                               label='Dados Experimentais')
                else:
                    ax.scatter(t_data, qt_data, color='black', s=50, 
                              label='Dados Experimentais')
                
                # Calcular predi√ß√µes suaves para o modelo
                t_curve, qt_curve = generate_smooth_curve(model_name, model_data['params'], t_data, n_curve_points)
                if t_curve is not None and qt_curve is not None:
                    chi2_text = f", œá¬≤ = {model_data['chi2_red']:.3f}" if model_data['chi2_red'] is not None else ""
                    ax.plot(t_curve, qt_curve, color='red', linewidth=2, 
                           label=f'{model_name} (R¬≤ = {model_data["r2"]:.4f}{chi2_text})')
                
                ax.set_xlabel('Tempo')
                ax.set_ylabel('qt')
                ax.set_title(f'Ajuste - {model_name}' + (' (com pesos)' if use_weights else ''))
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                st.pyplot(fig)
                
                # Gr√°fico de res√≠duos
                residuals = qt_data - model_data['qt_pred']
                
                fig_res, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
                
                # Res√≠duos vs tempo
                ax1.scatter(t_data, residuals, color='blue', alpha=0.6)
                ax1.axhline(y=0, color='red', linestyle='--', alpha=0.8)
                ax1.set_xlabel('Tempo')
                ax1.set_ylabel('Res√≠duos')
                ax1.set_title('Res√≠duos vs Tempo')
                ax1.grid(True, alpha=0.3)
                
                # Res√≠duos vs valores preditos
                ax2.scatter(model_data['qt_pred'], residuals, color='green', alpha=0.6)
                ax2.axhline(y=0, color='red', linestyle='--', alpha=0.8)
                ax2.set_xlabel('Valores Preditos')
                ax2.set_ylabel('Res√≠duos')
                ax2.set_title('Res√≠duos vs Valores Preditos')
                ax2.grid(True, alpha=0.3)
                
                st.pyplot(fig_res)
                
            else:
                st.error(f"Modelo {model_name} n√£o p√¥de ser ajustado")
    
    # Exportar resultados
    st.subheader("Exportar Resultados")
    
    if st.button("Gerar Arquivo de Exporta√ß√£o"):
        # Criar DataFrame com todos os resultados
        export_data = {
            st.session_state.time_col: t_data,
            st.session_state.qt_col: qt_data
        }
        
        if sigma_data is not None:
            export_data[f'desvio_padrao_{st.session_state.qt_col}'] = sigma_data
        
        # Adicionar predi√ß√µes nos pontos experimentais
        for model_name, model_data in results.items():
            if model_data is not None:
                export_data[f'{model_name}_pred_experimental'] = model_data['qt_pred']
                export_data[f'{model_name}_residuals'] = qt_data - model_data['qt_pred']
        
        export_df = pd.DataFrame(export_data)
        
        # Gerar curvas suaves para exporta√ß√£o
        st.info(f"üìä Gerando curvas com {n_curve_points} pontos para exporta√ß√£o...")
        
        curves_data = {}
        t_smooth = np.linspace(np.min(t_data), np.max(t_data), n_curve_points)
        curves_data['tempo_curva'] = t_smooth
        
        curves_info = []
        for model_name, model_data in results.items():
            if model_data is not None:
                t_curve, qt_curve = generate_smooth_curve(model_name, model_data['params'], t_data, n_curve_points)
                if t_curve is not None and qt_curve is not None:
                    curves_data[f'{model_name}_curva'] = qt_curve
                    curves_info.append(f"{model_name}: {len(qt_curve)} pontos")
        
        if curves_info:
            st.success(f"‚úÖ Curvas geradas: {', '.join(curves_info)}")
        else:
            st.warning("‚ö†Ô∏è Nenhuma curva foi gerada")
        
        curves_df = pd.DataFrame(curves_data)
        
        # Criar arquivo Excel em mem√≥ria
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # Aba com dados experimentais e predi√ß√µes nos pontos experimentais
            export_df.to_excel(writer, sheet_name='Dados_Experimentais', index=False)
            
            # Aba com curvas suaves para gr√°ficos
            curves_df.to_excel(writer, sheet_name='Curvas_Ajustadas', index=False)
            
            # Aba com par√¢metros e incertezas detalhada
            params_data = []
            for model_name, model_data in results.items():
                if model_data is not None:
                    # Adicionar uma linha de cabe√ßalho para cada modelo
                    params_data.append({
                        'Modelo': f'=== {model_name} ===',
                        'Par√¢metro': '',
                        'Valor': '',
                        'Incerteza': '',
                        'R¬≤': '',
                        'Chi¬≤ Reduzido': ''
                    })
                    
                    # Par√¢metros com incertezas
                    for param, value in model_data['params'].items():
                        param_std_key = f"{param}_std"
                        uncertainty = model_data['param_std'].get(param_std_key, 0)
                        params_data.append({
                            'Modelo': model_name,
                            'Par√¢metro': param,
                            'Valor': value,
                            'Incerteza': uncertainty,
                            'R¬≤': '',
                            'Chi¬≤ Reduzido': ''
                        })
                    
                    # M√©tricas na mesma linha
                    chi2_value = model_data['chi2_red'] if model_data['chi2_red'] is not None else 'N/A'
                    params_data.append({
                        'Modelo': model_name,
                        'Par√¢metro': 'M√©tricas',
                        'Valor': '',
                        'Incerteza': '',
                        'R¬≤': model_data['r2'],
                        'Chi¬≤ Reduzido': chi2_value
                    })
                    
                    # Equa√ß√£o
                    params_data.append({
                        'Modelo': model_name,
                        'Par√¢metro': 'Equa√ß√£o',
                        'Valor': model_data['equation'],
                        'Incerteza': '',
                        'R¬≤': '',
                        'Chi¬≤ Reduzido': ''
                    })
                    
                    # Linha em branco para separar modelos
                    params_data.append({
                        'Modelo': '',
                        'Par√¢metro': '',
                        'Valor': '',
                        'Incerteza': '',
                        'R¬≤': '',
                        'Chi¬≤ Reduzido': ''
                    })
            
            params_df = pd.DataFrame(params_data)
            params_df.to_excel(writer, sheet_name='Parametros_e_Incertezas', index=False)
            
            # Aba adicional com resumo estat√≠stico
            summary_data = []
            if use_weights:
                summary_data.append({
                    'Informa√ß√£o': 'Tipo de Ajuste',
                    'Valor': 'Ajuste Ponderado (com pesos baseados no desvio padr√£o)'
                })
                summary_data.append({
                    'Informa√ß√£o': 'Fun√ß√£o Peso',
                    'Valor': 'w = 1/œÉ¬≤'
                })
            else:
                summary_data.append({
                    'Informa√ß√£o': 'Tipo de Ajuste',
                    'Valor': 'Ajuste Sem Pesos (peso uniforme)'
                })
            
            summary_data.append({
                'Informa√ß√£o': 'N√∫mero de Pontos Experimentais',
                'Valor': len(t_data)
            })
            
            summary_data.append({
                'Informa√ß√£o': 'N√∫mero de Pontos nas Curvas',
                'Valor': n_curve_points
            })
            
            summary_data.append({
                'Informa√ß√£o': 'Melhor Modelo (R¬≤)',
                'Valor': max([(name, data['r2']) for name, data in results.items() if data is not None], 
                           key=lambda x: x[1])[0] if any(data is not None for data in results.values()) else 'N/A'
            })
            
            if use_weights:
                best_chi2_model = min([(name, data['chi2_red']) for name, data in results.items() 
                                     if data is not None and data['chi2_red'] is not None], 
                                    key=lambda x: x[1], default=('N/A', 'N/A'))
                summary_data.append({
                    'Informa√ß√£o': 'Melhor Modelo (œá¬≤)',
                    'Valor': best_chi2_model[0]
                })
            
            # Informa√ß√µes sobre as abas do arquivo
            summary_data.append({
                'Informa√ß√£o': '--- ESTRUTURA DO ARQUIVO ---',
                'Valor': ''
            })
            summary_data.append({
                'Informa√ß√£o': 'Aba: Dados_Experimentais',
                'Valor': 'Dados originais + predi√ß√µes nos pontos experimentais + res√≠duos'
            })
            summary_data.append({
                'Informa√ß√£o': 'Aba: Curvas_Ajustadas',
                'Valor': f'Curvas suaves com {n_curve_points} pontos para gr√°ficos'
            })
            summary_data.append({
                'Informa√ß√£o': 'Aba: Parametros_e_Incertezas',
                'Valor': 'Par√¢metros ajustados com suas incertezas e m√©tricas'
            })
            summary_data.append({
                'Informa√ß√£o': 'Aba: Resumo_Ajuste',
                'Valor': 'Esta aba - informa√ß√µes gerais sobre o ajuste'
            })
            
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='Resumo_Ajuste', index=False)
        
        output.seek(0)
        
        # Bot√£o de download
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        weighted_text = "_ponderado" if use_weights else "_sem_peso"
        st.download_button(
            label="üì• Baixar Resultados (Excel)",
            data=output.getvalue(),
            file_name=f"ajuste_cinetico{weighted_text}_{timestamp}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        
        # Mostrar informa√ß√µes sobre o arquivo exportado
        st.success("‚úÖ Arquivo gerado com sucesso!")
        st.info("""
        **üìã Estrutura do arquivo Excel:**
        
        üì∏ **Dados_Experimentais:** Seus dados originais + predi√ß√µes nos pontos experimentais + res√≠duos
        
        üì∏ **Curvas_Ajustadas:** Curvas suaves para criar gr√°ficos elegantes (tempo_curva + curvas de cada modelo)
        
        üì∏ **Parametros_e_Incertezas:** Par√¢metros ajustados com incertezas, R¬≤, œá¬≤ e equa√ß√µes
        
        üì∏ **Resumo_Ajuste:** Informa√ß√µes gerais sobre o tipo de ajuste e configura√ß√µes
        """)

else:
    st.info("üëÜ Carregue um arquivo Excel na barra lateral para come√ßar a an√°lise")
    
    # Informa√ß√µes sobre os modelos
    st.subheader("Modelos Cin√©ticos Dispon√≠veis")
    
    st.markdown("""
    **1. Pseudo-Second Order:**
    - Equa√ß√£o: qt = (k‚ÇÇ √ó q‚Çë¬≤ √ó t) / (1 + k‚ÇÇ √ó q‚Çë √ó t)
    - Par√¢metros: k‚ÇÇ (constante de velocidade), q‚Çë (capacidade de equil√≠brio)
    
    **2. Intraparticle Diffusion:**
    - Equa√ß√£o: qt = k‚Çö √ó ‚àöt + C
    - Par√¢metros: k‚Çö (constante de difus√£o), C (intercepto)
    
    **3. Elovich:**
    - Equa√ß√£o: qt = (1/Œ≤) √ó ln(Œ± √ó Œ≤) + (1/Œ≤) √ó ln(t)
    - Par√¢metros: Œ± (velocidade inicial de adsor√ß√£o), Œ≤ (constante de dessor√ß√£o)
    """)
    
    st.subheader("Formato do Arquivo")
    st.markdown("""
    - O arquivo deve estar em formato Excel (.xlsx ou .xls)
    - **Colunas esperadas:** tempo, qe, desvio padr√£o de qe
    - Os dados devem estar organizados em colunas
    - Valores faltantes ser√£o automaticamente removidos
    - O desvio padr√£o ser√° usado como peso no ajuste (peso = 1/œÉ¬≤)
    """)
    
    st.subheader("Ajuste com Pesos")
    st.markdown("""
    **Quando voc√™ fornecer os desvios padr√£o:**
    - Os pontos com menor incerteza ter√£o maior peso no ajuste
    - Ser√° calculado o œá¬≤ reduzido para avaliar a qualidade do ajuste
    - As incertezas dos par√¢metros ser√£o calculadas
    - Os gr√°ficos mostrar√£o barras de erro
    - O R¬≤ ser√° calculado de forma ponderada
    
    **M√©tricas de qualidade:**
    - **R¬≤ ponderado:** Coeficiente de determina√ß√£o considerando os pesos
    - **œá¬≤ reduzido:** Deve estar pr√≥ximo de 1 para um bom ajuste
    - **Incertezas dos par√¢metros:** Propaga√ß√£o de erros atrav√©s da matriz de covari√¢ncia
    """)
    
    st.subheader("Novo! üéØ Exporta√ß√£o Aprimorada")
    st.markdown("""
    **O arquivo Excel agora inclui:**
    
    üìä **Curvas Ajustadas:** Dados suaves para criar gr√°ficos profissionais
    
    üìà **Duas escalas de dados:**
    - Predi√ß√µes nos pontos experimentais (para an√°lise de res√≠duos)
    - Curvas suaves interpoladas (para visualiza√ß√£o gr√°fica)
    
    ‚öôÔ∏è **Controle de resolu√ß√£o:** Configure quantos pontos usar nas curvas (100-1000 pontos, padr√£o: 300)
    
    üìÅ **Estrutura organizada:** Cada tipo de informa√ß√£o em abas separadas para facilitar o uso
    """)
